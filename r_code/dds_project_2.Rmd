---
title: "dds_project_2"
author: "Jake"
date: "2023-04-09"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(class)
library(caret)
library(ggcorrplot)
library(ggthemes)
library(e1071)
library(plotly)
library(smotefamily)

```

# Job Role Specific Trend
Here we uncovered that certain jobs tend to have a spike or dip for satisfaction as well as performance at the start. We believe that this has something to do with an employee getting more use to their job as well as them potentially getting ready for a promotion. We believe that the evidence suggests if the employee doesn't get their promotion their satisfaction and performance deteriorate as a result.

``` {r Job Role Specific Trend, warning=FALSE}
# Read in data set
job_role_exploration = read.csv('../raw_data/CaseStudy2-data.csv')

# drop columns with only one value as they are not adding any value
job_role_exploration_clean_data <- job_role_exploration[vapply(job_role_exploration, function(x) length(unique(x)) > 1, logical(1L))]

job_role_exploration_clean_data %>%
  ggplot(aes(x=YearsInCurrentRole, y=JobSatisfaction, color=JobRole)) +
  geom_smooth() +
  facet_wrap(~ JobRole) +
  labs(x="Years in Current Role", y="Job Satisfaction", title="Job Satisfaction by Job Role and Years in Current Role")

job_role_exploration_clean_data %>%
  ggplot(aes(x=YearsInCurrentRole, y=PerformanceRating, color=JobRole)) +
  geom_smooth() +
  facet_wrap(~ JobRole) +
  labs(x="Years in Current Role", y="Performance Rating", title="Performance Rating by Job Role and Years in Current Role")


```

# Other Interesting Trend
Another interesting fact we found in data exploration is that employees have a much higher chance of attrition during year 0 and year 2 which further helps prove out that if an employee doesn't get a promotion especially in "earlier" and "higher" risk times for attrition such as a Sales Representative the evidence suggests they are more likely to leave.

``` {r Other Interesting Trend}
interesting_attrition_exploration = read.csv('../raw_data/CaseStudy2-data.csv')

# drop columns with only one value as they are not adding any value
interesting_attrition_exploration_clean_data <- interesting_attrition_exploration[vapply(interesting_attrition_exploration, function(x) length(unique(x)) > 1, logical(1L))]


# Years in current role with attrition. 
# Note: 0 and 2 years seem to be the most likely to have attrition.
interesting_attrition_exploration_clean_data %>%
  ggplot(aes(x=YearsInCurrentRole, fill=Attrition)) +
    geom_bar(position="dodge") +
    facet_wrap(~ JobRole)+
    labs(x="Years in Current Role", y="Attrition", 
         title="Attrition Count by Job Role and Years in Current Role")


```

# Top Three Features for Attrition
The Top features are:
  * Worker Type
  * Survey Results
  * Career Type

These are features that were engineered during our process. The mapping to how these features are created can be found below. The general process was to chart the features we were interested in and rank their likelihood of attrition into 1 - 5 buckets. 1 being the worst and 5 being the best. These features were then added together to create the desired "summary" or engineered feature.

We also balanced the data set using SMOTE as this will help our models better predict on new data.

```{r Top Three Features for Attrition}
#############
# Load Data #
#############

# Read in data set
attrition_raw_data = read.csv('../raw_data/CaseStudy2-data.csv')

# drop columns with only one value as they are not adding any value
attrition_clean_data <- attrition_raw_data[vapply(attrition_raw_data, function(x) length(unique(x)) > 1, logical(1L))]

####################
# Data Exploration #
####################

# Create factor variables
attrition_factors_data <- attrition_clean_data
attrition_factors_data[sapply(attrition_factors_data, is.character)] <- lapply(attrition_clean_data[sapply(attrition_clean_data, is.character)], as.factor)

# Create correlation for all features
corr_no_feature <- model.matrix(~0+., data=attrition_factors_data) %>% 
          cor(use="pairwise.complete.obs") 

# Show how all variables correlate to Attrition Yes and Attrition No
filtered_corr <- data.frame(corr_no_feature) %>% 
                  filter(rownames(corr_no_feature) %in% c('AttritionNo', 'AttritionYes'))

# Arrange variables correlation so we can understand which variables matter the most
data.frame(t(filtered_corr)) %>%
  arrange(abs(AttritionNo))

# Years in current role with attrition. 
# Note: 0 and 2 years seem to be the most likely to have attrition.
attrition_raw_data %>%
  select(Attrition, YearsInCurrentRole) %>%
  ggplot(aes(x=YearsInCurrentRole, fill=Attrition)) +
    geom_bar(position="dodge")

# Years since last promotion with attrition
# Note: Attrition rates tend go down from 0 - 5 year than back up from 5 - 7 then down again.
attrition_raw_data %>%
  select(Attrition, YearsSinceLastPromotion) %>%
  ggplot(aes(x=YearsSinceLastPromotion, fill=Attrition)) +
    geom_bar(position="dodge")

# Years per Company (Total Working Years / Number of Companies worked for) with attrition
# Note: Attrition tends to go down from 0 - 4 years then back up at 5 and then back down again.
# Note: An assumption is made that 0 for NumCompaniesWorked means you have only worked for Frito Lay. To make the formula work we add 1 to all values in the NumCompaniesWorked column.
attrition_raw_data %>%
  mutate(TotalWorkingYears = if_else(TotalWorkingYears=='0', 1,
                                     as.double(TotalWorkingYears))) %>%
  mutate(NumCompaniesWorked = NumCompaniesWorked + 1) %>% # assumption
  mutate(YearsPerCompany = as.integer(TotalWorkingYears / NumCompaniesWorked)) %>%
  select(Attrition, YearsPerCompany) %>%
  ggplot(aes(x=YearsPerCompany, fill=Attrition)) +
    geom_bar(position="dodge")

#######################
# Feature Engineering #
#######################

# Create a data set with some feature engineering based on what we have observed.
attrition_feature_enginering <- attrition_clean_data %>%
  # Job Type Risk
  mutate(job_type_risk = case_when(JobRole %in% 
                                     c("Healthcare Representative",
                                       "Laboratory Technician",
                                       "Research Scientist",
                                       "Sales Executive",
                                       "Sales Representative") ~ "High Risk",
                                    TRUE ~ "Low Risk")
         ) %>%
  mutate_at(vars(job_type_risk), as.factor) %>%
  # Survey Results
  mutate(survey_results = 
           JobInvolvement + JobSatisfaction + WorkLifeBalance) %>%
  # Worker Type
  mutate(worker_type = case_when(OverTime=='Yes' ~ 1,
                                 OverTime=='No' ~ 5) + 
                       case_when(MaritalStatus=='Married' ~ 5,
                                 MaritalStatus=='Divorced' ~ 3,
                                 MaritalStatus=='Single' ~ 1) +
                       JobLevel) %>%
  # Career Type
  # Create YearsPerCompany
  mutate(TotalWorkingYears = if_else(TotalWorkingYears=='0', 1,
                                    as.double(TotalWorkingYears))) %>%
  mutate(NumCompaniesWorked = NumCompaniesWorked + 1) %>% # assumption
  mutate(YearsPerCompany = as.integer(TotalWorkingYears / NumCompaniesWorked)) %>%
  # Create career_type
  mutate(career_type = case_when(YearsPerCompany==0 ~ 1,
                                 YearsPerCompany==1 ~ 2,
                                 YearsPerCompany==2 ~ 3,
                                 YearsPerCompany==3 ~ 4,
                                 TRUE ~ 5) +
                       case_when(YearsInCurrentRole==0 ~ 1,
                                 YearsInCurrentRole==2 ~ 2,
                                 YearsInCurrentRole==7 ~ 3,
                                 YearsInCurrentRole %in% c(1, 3, 4) ~ 4,
                                 TRUE ~ 5) +
                       case_when(YearsSinceLastPromotion==0 ~ 1,
                                 YearsSinceLastPromotion==1 ~ 2,
                                 YearsSinceLastPromotion==2 ~ 3,
                                 YearsSinceLastPromotion==7 ~ 4,
                                 TRUE ~ 5)
         ) %>%
  
  select(Attrition, job_type_risk, survey_results, worker_type, career_type) 

# Create factor variables
attrition_factors_data_with_enginering <- attrition_feature_enginering
attrition_factors_data_with_enginering[sapply(attrition_factors_data_with_enginering, is.character)] <- lapply(attrition_clean_data[sapply(attrition_clean_data, is.character)], as.factor)

# Create correlation for all engineered features
corr <- model.matrix(~0+., data=attrition_factors_data_with_enginering) %>% 
          cor(use="pairwise.complete.obs") 

# Create correlation with visual 
model.matrix(~0+., data=attrition_factors_data_with_enginering) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag=FALSE, type="lower", lab=TRUE, lab_size=2)

####################
# Balance Data set #
####################

# Data set imbalanced
attrition_factors_data_with_enginering %>%
  ggplot(aes(Attrition, fill=Attrition)) +
  geom_bar() +
  labs(title='Attrition Count', x='Attrition', y='Count') +
  facet_wrap(~ job_type_risk) +
  theme_economist() +
  scale_fill_manual(values = c("blue", "red"))

# Convert job type risk into number
attrition_factors_data_with_enginering <- attrition_factors_data_with_enginering %>%
  mutate(job_type_risk = case_when(job_type_risk=="High Risk" ~ 0,
                                   job_type_risk=="Low Risk" ~ 15))

# Balance data set with SMOTE (Synthetic Minority Oversampling Technique)
smote_obj <- SMOTE(attrition_factors_data_with_enginering[, 2:ncol(attrition_factors_data_with_enginering)], attrition_factors_data_with_enginering[, 1])

# Get data out of smote object
balanced_attrition_factors_data_with_enginering <- smote_obj$data
# Rename class as Attrition
colnames(balanced_attrition_factors_data_with_enginering)[ncol(attrition_factors_data_with_enginering)] <- "Attrition"

# Convert job type risk back into string
balanced_attrition_factors_data_with_enginering <- balanced_attrition_factors_data_with_enginering %>%
  mutate(job_type_risk = case_when(job_type_risk==0 ~ "High Risk",
                                   job_type_risk==15 ~ "Low Risk"))


# Data set now balanced
balanced_attrition_factors_data_with_enginering %>%
  ggplot(aes(Attrition, fill=Attrition)) +
  geom_bar() +
  labs(title='Attrition Count', x='Attrition', y='Count') +
  facet_wrap(~ job_type_risk) +
  theme_economist() +
  scale_fill_manual(values = c("blue", "red"))

###########
# 3D Plot #
###########
balanced_attrition_factors_data_with_enginering_high <- balanced_attrition_factors_data_with_enginering %>%
  filter(job_type_risk == "High Risk")
balanced_attrition_factors_data_with_enginering_low <- balanced_attrition_factors_data_with_enginering %>%
  filter(job_type_risk == "Low Risk")

plot_ly(x=balanced_attrition_factors_data_with_enginering_high$survey_results,
        y=balanced_attrition_factors_data_with_enginering_high$worker_type,
        z=balanced_attrition_factors_data_with_enginering_high$career_type,
        type="scatter3d", 
        mode="markers",
        color=balanced_attrition_factors_data_with_enginering_high$Attrition) %>%
  layout(scene=list(xaxis=list(title="Survery Results"),
                    yaxis=list(title="Worker Type"),
                    zaxis=list(title="Career Type")),
         title="High Risk Jobs: Attrition by Survey Results and Worker/Career Type")

plot_ly(x=balanced_attrition_factors_data_with_enginering_low$survey_results,
        y=balanced_attrition_factors_data_with_enginering_low$worker_type,
        z=balanced_attrition_factors_data_with_enginering_low$career_type,
        type="scatter3d", 
        color=balanced_attrition_factors_data_with_enginering_low$Attrition) %>%
  layout(scene=list(xaxis=list(title="Survery Results"),
                    yaxis=list(title="Worker Type"),
                    zaxis=list(title="Career Type")),
         title="Low Risk Jobs: Attrition by Survey Results and Worker/Career Type")


#################################
# Ideas for Future Improvements #
#################################

## Data Exploration
# R Shiny app for creating graphs so exploration of new/other features is easier 
# It would be nice if feature engineering / combination of features could be abstracted so end user could "create" features based on domain knowledge
# Maybe scale features instead of hard coding values 1 - 5 based on observations
```
# Attrition Model
Here we test out both KNN and Naive Bayes on predicting attrition. It is clear that the model that preformed best on this data set was KNN.

```{r Model Attrition}
#############
# KNN Model #
#############

knn_loop <- function(iterations, num_of_k_s, split_percent, data_for_model,
                     data_start_column, data_end_column, label_column) {
  # This functions assumes all labeling data is either at the end or the 
  # beginning of your data frame.
  masterAcc = matrix(nrow = iterations, ncol = numks)
  masterSens = matrix(nrow = iterations, ncol = numks)
  masterSpec = matrix(nrow = iterations, ncol = numks)

  for(j in 1:iterations)
  {
    accs = data.frame(accuracy = numeric(numks), k = numeric(numks))
    trainIndices = sample(1:dim(data_for_model)[1],
                        round(splitPerc * dim(data_for_model)[1]))
    train = data_for_model[trainIndices,]
    test = data_for_model[-trainIndices,]
    for(i in 1:numks)
    {
      classifications = knn(train[,data_start_column:data_end_column], 
                            test[,data_start_column:data_end_column], 
                            train[[label_column]], 
                            k = i, 
                            prob = TRUE
                            )
      CM = confusionMatrix(table(classifications, test[[label_column]]))
      # Write to Accuracy Table
      masterAcc[j,i] = CM$overall[1]
      # Write to Sensitivity Table
      masterSens[j,i] = CM$byClass[1]
      # Write to Specificity Table
      masterSpec[j,i] = CM$byClass[2]
    }
  }
  
  MeanAcc = colMeans(masterAcc)
  MeanSens = colMeans(masterSens)
  MeanSpec = colMeans(masterSpec)
  
  ReturnObj <- c(MeanAcc, MeanSens, MeanSpec)
  
  return(ReturnObj)
}

# Set up parameters for loop
iterations_knn = 500
numks = 10
splitPerc = .7

# Convert job type risk into number
balanced_attrition_factors_data_with_enginering <- balanced_attrition_factors_data_with_enginering %>%
  mutate(job_type_risk = case_when(job_type_risk=="High Risk" ~ 0,
                                   job_type_risk=="Low Risk" ~ 15))

# Run the loop for the desired amount of iterations and values for k
KNN_results = 
  knn_loop(iterations=iterations_knn, num_of_k_s=numks, split_percent=splitPerc,
           data_for_model=balanced_attrition_factors_data_with_enginering, 
           data_start_column=1, 
           data_end_column=(ncol(balanced_attrition_factors_data_with_enginering) - 1),
           label_column="Attrition")

# Turn MeanAcc_knn into a data frame
sequence_of_k_s = seq(1,numks,1)
Mean_Acc_df = as.data.frame(KNN_results[1:10])
colnames(Mean_Acc_df)[1] <- "Accuracy"
Mean_Acc_df$K_value = sequence_of_k_s

Mean_Sens_df = as.data.frame(KNN_results[11:20])
colnames(Mean_Sens_df)[1] <- "Sensitivity"
Mean_Sens_df$K_value = sequence_of_k_s
  
Mean_Spec_df = as.data.frame(KNN_results[21:30])
colnames(Mean_Spec_df)[1] <- "Specificity"
Mean_Spec_df$K_value = sequence_of_k_s


knn_results_df <- merge(Mean_Acc_df, Mean_Sens_df, by="K_value")
knn_results_df <- merge(knn_results_df, Mean_Spec_df, by="K_value")
knn_results_df

# Create a graph of accuracy across all values for k
# Note: Looks like K = 3 is best value
knn_results_df %>%
  ggplot(aes(x=K_value)) +
  geom_line(aes(y=Accuracy, color="Accuracy")) +
  geom_line(aes(y=Sensitivity, color="Sensitivity")) +
  geom_line(aes(y=Specificity, color="Specificity")) +
  ggtitle("Model Metrics Across Values of K") +
  labs(x='Number for K', y='Model Metric Percent') +
  theme_economist()


###############
# Naive Bayes #
###############

naive_bayes_loop <- function(num_iteration, data_for_model, split_percent,
                             data_start_column, data_end_column, label_column) {
  masterAcc = matrix(nrow=num_iteration, ncol=3)
  colnames(masterAcc) <- c("Accuracy", "Sensitivity", "Specificity")
  
  for(i in 1:num_iteration)
    {
      set.seed(i)
      # Split the data into train and test based on sample with seed
      train_indices = sample(seq(1:length(data_for_model[[label_column]])), 
                           round(split_percent * length(data_for_model[[label_column]])))
    
      # Create the train and test data based on previous sample split
      train = data_for_model[train_indices,]
      test = data_for_model[-train_indices,]
      
      model = naiveBayes(train[, data_start_column:data_end_column],
                         train[[label_column]])
      
      
      CM = confusionMatrix(table(predict(model,
                                         test[, data_start_column:data_end_column]), 
                                         test[[label_column]]
                                 )
                           )
      masterAcc[i, "Accuracy"] = CM$overall[1] # Attach accuracy for loop
      masterAcc[i, "Sensitivity"] = CM$byClass[1] # Attach sensitivity for loop
      masterAcc[i, "Specificity"] = CM$byClass[2] # Attach specificity for loop
  }
  
  return(masterAcc)
}


# Set up parameters for loop
nb_iterations = 100
nb_split_percent = .7

MeanAcc_NB = 
  naive_bayes_loop(num_iteration=nb_iterations, 
                   data_for_model=balanced_attrition_factors_data_with_enginering, 
                   split_percent=nb_split_percent, data_start_column=1,
                   data_end_column=(ncol(balanced_attrition_factors_data_with_enginering) - 1),
                   label_column="Attrition")


print("Mean of Accuracy")
mean(MeanAcc_NB[, "Accuracy"])
print("Mean of Sensitivity")
mean(MeanAcc_NB[, "Sensitivity"])
print("Mean of Specificity")
mean(MeanAcc_NB[, "Specificity"])

#################################
# Ideas for Future Improvements #
#################################
## KNN Model
# Make model metrics data frame a little more dynamic / clean

## Naive Bayes
# I think we could work on featuring engineering for this type of model specifically maybe?

## Add: Ensemble for both models
```

# Salery Data Exploration
Here we first pick variables that seem to have an impact on salary. From here we run a LM to see how well each variable preforms with data.  

``` {r Salary Data Exploration}
#############
# Load Data #
#############

# Read in data set
salary_raw_data = read.csv('../raw_data/CaseStudy2-data.csv')

# drop columns with only one value as they are not adding any value
salary_clean_data <- salary_raw_data[vapply(salary_raw_data, function(x) length(unique(x)) > 1, logical(1L))]

# Create factor variables
salary_factors_data <- salary_clean_data
salary_factors_data[sapply(salary_factors_data, is.character)] <- lapply(salary_clean_data[sapply(salary_clean_data, is.character)], as.factor)

###################################
# Find Most Significant Variables #
###################################

# find the best combination of variables to use for our model
salary_model <- lm(MonthlyIncome ~ MonthlyRate + StockOptionLevel + YearsAtCompany + TotalWorkingYears +
                                   YearsSinceLastPromotion + YearsWithCurrManager + JobInvolvement + Age + 
                                   JobLevel + JobRole + Gender + Education + Department + DailyRate + BusinessTravel + 
                                   HourlyRate, 
                   data=salary_factors_data)
summary(salary_model)
confint(salary_model)

#######################################
# Drop Insignificant Factor Variables #
#######################################

salary_factors_w_dropped_factor_levels_data <- salary_factors_data
salary_factors_w_dropped_factor_levels_data$JobRole <- 
  droplevels(salary_factors_w_dropped_factor_levels_data$JobRole,
             exclude=c(''))

#################################
# Ideas for Future Improvements #
#################################
## Load Data
# Make Load Data the data a function so its more repeatable

```

# Salery Model
Once we have that we picked the best two models (including and excluding Job Role with Total working years, Job Level, and Years since last promotion) we found that including Job Role helps the model and picked that model to use in predicting.

Below is also a 6 step Hypothesis test to show significance.

``` {r Model Salery}

###################################################
# Create Models Based on Most Impactful Variables #
###################################################

# specify the cross-validation method
ctrl <- trainControl(method = "LOOCV")

# Fit the models
salary_model_wo_JobRole <- train(MonthlyIncome ~ TotalWorkingYears + JobLevel + YearsSinceLastPromotion, 
                                 method='lm', data=salary_factors_data)

salary_model_w_JobRole <- train(MonthlyIncome ~ TotalWorkingYears + JobLevel + JobRole + YearsSinceLastPromotion, 
                                method='lm', data=salary_factors_data)

# With Leave One Out Cross Validation find best model
salary_model_wo_JobRole # Worst: RMSE = 1401.708
salary_model_w_JobRole # Best: RMSE = 1082.55

best_known_salary_model <- lm(MonthlyIncome ~ TotalWorkingYears + JobLevel + JobRole + YearsSinceLastPromotion, 
                              data=salary_factors_data)
summary(best_known_salary_model)
confint(best_known_salary_model)

##########################
# 6 Step Hypothesis Test #
##########################

# All based on Summary and Confint from above
# This is one example for Total Working years
# Note: not all factors for Job Role are significant but overall the factors that are impactful are enough to warrant including in model.

# Step 1: Identify the null and alternative hypothesis 
#   Ho: B1 = 0
#   Ha: B1 != 0
#   a = 0.05

# Step 3: Find the test statistic
# T = Bo^ / SE(Bo^)
# T = 45.109 / 8.388 = 5.378

# Step 4: Find the P Value
# 9.71e-08

# Step 5: Reject Ho

# Step 6: There is overwhelming evidence to suggest that the slope is different from zero. Out estimate for Total Working Years is 45.109 (Total Working Years)and we are 95% confident that the intercept is between 28.64 and 61.57


#################################
# Ideas for Future Improvements #
#################################
## Create Model Based on Most Impactful Variables
# Pull variables from the previous module (Find Most Significant Variables) automatically?
# Pick top 3 possible models automatically
```



``` {r Predicting Test Data}
#############
# Load Data #
#############
salary_raw_predict_data = read.csv('../raw_data/CaseStudy2CompSet No Salary.csv')
attrition_raw_predict_data = read.csv('../raw_data/CaseStudy2CompSet No Attrition.csv')

########################
# Attrition Prediction #
########################

# drop columns with only one value as they are not adding any value
attrition_prediction_clean_data <- attrition_raw_predict_data[vapply(attrition_raw_predict_data, function(x) length(unique(x)) > 1, logical(1L))]

# Create a data set with some feature engineering based on what we have observed.
attrition_prediction_feature_enginering <- attrition_prediction_clean_data %>%
  # Job Type Risk
  mutate(job_type_risk = case_when(JobRole %in% 
                                     c("Healthcare Representative",
                                       "Laboratory Technician",
                                       "Research Scientist",
                                       "Sales Executive",
                                       "Sales Representative") ~ "High Risk",
                                    TRUE ~ "Low Risk")
         ) %>%
  mutate_at(vars(job_type_risk), as.factor) %>%
  # Survey Results
  mutate(survey_results = 
           JobInvolvement + JobSatisfaction + WorkLifeBalance) %>%
  # Worker Type
  mutate(worker_type = case_when(OverTime=='Yes' ~ 1,
                                 OverTime=='No' ~ 5) + 
                       case_when(MaritalStatus=='Married' ~ 5,
                                 MaritalStatus=='Divorced' ~ 3,
                                 MaritalStatus=='Single' ~ 1) +
                       JobLevel) %>%
  # Career Type
  # Create YearsPerCompany
  mutate(TotalWorkingYears = if_else(TotalWorkingYears=='0', 1,
                                    as.double(TotalWorkingYears))) %>%
  mutate(NumCompaniesWorked = NumCompaniesWorked + 1) %>% # assumption
  mutate(YearsPerCompany = as.integer(TotalWorkingYears / NumCompaniesWorked)) %>%
  # Create career_type
  mutate(career_type = case_when(YearsPerCompany==0 ~ 1,
                                 YearsPerCompany==1 ~ 2,
                                 YearsPerCompany==2 ~ 3,
                                 YearsPerCompany==3 ~ 4,
                                 TRUE ~ 5) +
                       case_when(YearsInCurrentRole==0 ~ 1,
                                 YearsInCurrentRole==2 ~ 2,
                                 YearsInCurrentRole==7 ~ 3,
                                 YearsInCurrentRole %in% c(1, 3, 4) ~ 4,
                                 TRUE ~ 5) +
                       case_when(YearsSinceLastPromotion==0 ~ 1,
                                 YearsSinceLastPromotion==1 ~ 2,
                                 YearsSinceLastPromotion==2 ~ 3,
                                 YearsSinceLastPromotion==7 ~ 4,
                                 TRUE ~ 5)
         ) %>%
  
  select(job_type_risk, survey_results, worker_type, career_type) 

# Create factor variables
attrition_prediction_factors_data_with_enginering <- attrition_prediction_feature_enginering
attrition_prediction_factors_data_with_enginering[sapply(attrition_prediction_factors_data_with_enginering, is.character)] <- lapply(attrition_prediction_clean_data[sapply(attrition_prediction_clean_data, is.character)], as.factor)

# Convert job type risk into number
attrition_prediction_factors_data_with_enginering <- attrition_prediction_factors_data_with_enginering %>%
  mutate(job_type_risk = case_when(job_type_risk=="High Risk" ~ 0,
                                   job_type_risk=="Low Risk" ~ 15))

balanced_attrition_factors_data_with_enginering
attrition_prediction_factors_data_with_enginering

attrition_prediction <- knn(balanced_attrition_factors_data_with_enginering[, 1:4], 
    attrition_prediction_factors_data_with_enginering, 
    balanced_attrition_factors_data_with_enginering$Attrition, 
    k = 3
    )

attrition_prediction <- as.data.frame(attrition_prediction)

write.csv(attrition_prediction, "../prediction_results/Case2PredictionsRastberger Attrition.csv")

#####################
# Salary Prediction #
#####################

salary_prediction <- predict(best_known_salary_model, newdata=salary_raw_predict_data)
write.csv(salary_prediction, "../prediction_results/Case2PredictionsRastberger Salary.csv")
```
